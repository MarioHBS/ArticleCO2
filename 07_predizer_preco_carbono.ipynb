{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição de Preço de Carbono\n",
    "Este notebook realiza a predição do preço de carbono utilizando diferentes modelos de machine learning. O processo inclui carregamento e preparação de dados, treinamento de modelos e avaliação de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas Necessárias\n",
    "Nesta etapa, importamos as bibliotecas essenciais para manipulação de dados, visualização e modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Configuração de estilo para gráficos\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento do Dataset Consolidado\n",
    "Carregamos o dataset consolidado que contém informações como PIB, emissões de gases de efeito estufa (GEE) e desmatamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset consolidado\n",
    "INPUT_PATHS = {\"carbono_consolidado\": \"data/generated/carbono_serra_penitente.csv\"}\n",
    "df = pd.read_csv(INPUT_PATHS[\"carbono_consolidado\"], encoding='utf-8-sig')\n",
    "print(\"Colunas iniciais:\", df.columns.tolist())\n",
    "\n",
    "# Visualizar as primeiras linhas do dataset\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos Preços de Carbono\n",
    "Nesta etapa, carregamos os preços de carbono a partir de um arquivo Excel e transformamos os dados para o formato adequado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar preços de carbono\n",
    "price_path = \"data/raw/carbon-prices-latest.xlsx\"\n",
    "xls = pd.ExcelFile(price_path)\n",
    "sheet = xls.sheet_names[0]\n",
    "price_raw = pd.read_excel(xls, sheet_name=sheet, header=1)\n",
    "print(\"Colunas do sheet de preços:\", price_raw.columns.tolist())\n",
    "\n",
    "# Visualizar as primeiras linhas do dataset de preços\n",
    "display(price_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformação dos Dados de Preços\n",
    "Transformamos os dados de preços para o formato \"long\" e filtramos apenas os dados relevantes (EU ETS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar a coluna de instrumento e colunas de anos\n",
    "instrument_col = 'Instrument name'\n",
    "year_cols = [c for c in price_raw.columns if isinstance(c, int)]\n",
    "\n",
    "# Transformar preços em formato long\n",
    "df_price = price_raw.melt(\n",
    "    id_vars=[instrument_col],\n",
    "    value_vars=year_cols,\n",
    "    var_name='ano',\n",
    "    value_name='carbon_price_usd'\n",
    ")\n",
    "\n",
    "# Filtrar apenas o EU ETS\n",
    "df_price = df_price[df_price[instrument_col] == 'EU ETS']\n",
    "\n",
    "# Converter tipos\n",
    "df_price['ano'] = df_price['ano'].astype(int)\n",
    "df_price['carbon_price_usd'] = pd.to_numeric(df_price['carbon_price_usd'], errors='coerce')\n",
    "\n",
    "# Selecionar e limpar\n",
    "df_price = df_price[['ano', 'carbon_price_usd']].dropna().drop_duplicates()\n",
    "print(f\"Preços disponíveis: {df_price['ano'].min()}–{df_price['ano'].max()}\")\n",
    "\n",
    "# Visualizar os dados transformados\n",
    "display(df_price.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesclagem dos Dados\n",
    "Mesclamos os preços de carbono ao dataset principal com base no ano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesclar preços ao dataset principal\n",
    "df = df.merge(df_price, on='ano', how='inner')\n",
    "print(\"Dataset após merge:\", df.shape)\n",
    "\n",
    "# Visualizar as primeiras linhas do dataset mesclado\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregação de Dados por Município e Ano\n",
    "Agregamos os dados para evitar duplicações, mantendo uma linha única por município e ano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar dados por município e ano\n",
    "df = (\n",
    "    df.groupby(['municipio', 'ano'], as_index=False)\n",
    "      .agg({\n",
    "          'pib': 'first',                  # PIB já é único por muni-ano\n",
    "          'GEE_tCO2e': 'sum',              # soma emissões de todas as classes\n",
    "          'area_desmatada_ha': 'sum',      # soma área desmatada total\n",
    "          'carbon_price_usd': 'first'      # preço único por ano\n",
    "      })\n",
    ")\n",
    "print(\"Após agregação município-ano:\", df.shape)\n",
    "\n",
    "# Visualizar as primeiras linhas do dataset agregado\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação de Features e Target\n",
    "Selecionamos as colunas de features e a variável target para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar features e target\n",
    "FEATURE_COLS = ['pib', 'GEE_tCO2e', 'area_desmatada_ha']\n",
    "for col in FEATURE_COLS:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "target_col = 'carbon_price_usd'\n",
    "\n",
    "# Visualizar as features e target\n",
    "display(df[FEATURE_COLS + [target_col]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão dos Dados em Treino e Teste\n",
    "Dividimos os dados em conjuntos de treino e teste para validação do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão treino/teste\n",
    "X = df[FEATURE_COLS]\n",
    "y = df[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visualizar tamanhos dos conjuntos\n",
    "print(f\"Tamanho do treino: {X_train.shape}, Tamanho do teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padronização dos Dados\n",
    "Padronizamos os dados para melhorar o desempenho dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronização\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e Avaliação de Modelos\n",
    "Treinamos diferentes modelos de machine learning e avaliamos seus desempenhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir e treinar modelos\n",
    "modelos = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'KNN Regressor': KNeighborsRegressor(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'MLP Regressor': MLPRegressor(max_iter=1000, random_state=42),\n",
    "    'Lasso': Lasso(alpha=0.01, random_state=42),\n",
    "    'SVR': SVR(kernel='rbf'),\n",
    "    'Dummy': DummyRegressor(),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in modelos.items():\n",
    "    print(f\"Treinando {name}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    preds = model.predict(X_test_scaled)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    print(f\"{name} → R²: {r2:.3f}, MSE: {mse:.3f}\")\n",
    "    results.append({'model': name, 'R2': r2, 'MSE': mse})\n",
    "\n",
    "# Visualizar resultados\n",
    "df_res = pd.DataFrame(results)\n",
    "display(df_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização de Resultados\n",
    "Criamos um gráfico de dispersão para comparar os valores reais e previstos pelo melhor modelo (XGBoost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Gerar scatter Real vs Previsto para cada modelo\n",
    "fig_dir = os.path.dirname(OUTPUT_PATHS.scatter_xgboost_png)\n",
    "for model_name, model in modelos.items():\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    slug = model_name.lower().replace(' ', '_')\n",
    "    scatter_path = os.path.join(fig_dir, f\"scatter_real_vs_pred_{slug}.png\")\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.scatterplot(x=y_test, y=y_pred)\n",
    "    plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
    "    plt.xlabel('Real')\n",
    "    plt.ylabel('Previsto')\n",
    "    plt.title(f'Real vs Previsto – {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(scatter_path)\n",
    "    plt.close()\n",
    "    print(f\"Scatter salvo para {model_name} em: {scatter_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas necessárias\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from variaveis import FEATURE_COLS, INPUT_PATHS, OUTPUT_PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuração de Estilo de Plots\n",
    "Configura o estilo dos gráficos para melhor visualização e cria diretórios necessários para salvar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração de plots\n",
    "sns.set(style='whitegrid')\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATHS.scatter_xgboost_png), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar Dataset Consolidado\n",
    "Carrega o dataset consolidado contendo informações como PIB, GEE e desmatamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Carregar dataset consolidado (PIB, GEE, desmatamento)\n",
    "df = pd.read_csv(INPUT_PATHS.carbono_consolidado, encoding='utf-8-sig')\n",
    "print(\"Colunas iniciais:\", df.columns.tolist())\n",
    "# Visualizar as primeiras linhas do dataset\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar Preços de Carbono\n",
    "Carrega os preços de carbono a partir de um arquivo Excel e identifica as colunas relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Carregar preços de carbono\n",
    "price_path = INPUT_PATHS.carbon_prices_raw\n",
    "xls = pd.ExcelFile(price_path)\n",
    "sheet = xls.sheet_names[0]\n",
    "price_raw = pd.read_excel(xls, sheet_name=sheet, header=1)\n",
    "print(\"Colunas do sheet de preços:\", price_raw.columns.tolist())\n",
    "# Visualizar as primeiras linhas do dataset de preços\n",
    "display(price_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformar Preços em Formato Long\n",
    "Transforma os preços de carbono em formato long para facilitar a análise e filtra apenas os dados relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar a coluna de instrumento (Instrument name)\n",
    "instrument_col = 'Instrument name'\n",
    "# Identificar colunas de anos (tipos int)\n",
    "year_cols = [c for c in price_raw.columns if isinstance(c, int)]\n",
    "\n",
    "# 3) Transformar preços em formato long\n",
    "df_price = price_raw.melt(\n",
    "    id_vars=[instrument_col],\n",
    "    value_vars=year_cols,\n",
    "    var_name='ano',\n",
    "    value_name='carbon_price_usd'\n",
    ")\n",
    "# Filtrar apenas o EU ETS\n",
    "df_price = df_price[df_price[instrument_col] == 'EU ETS']\n",
    "# Converter tipos\n",
    "df_price['ano'] = df_price['ano'].astype(int)\n",
    "df_price['carbon_price_usd'] = pd.to_numeric(\n",
    "    df_price['carbon_price_usd'], errors='coerce')\n",
    "# Selecionar e limpar\n",
    "df_price = df_price[['ano', 'carbon_price_usd']].dropna().drop_duplicates()\n",
    "print(f\"Preços disponíveis: {df_price['ano'].min()}–{df_price['ano'].max()}\")\n",
    "# Visualizar os preços transformados\n",
    "display(df_price.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesclar Preços ao Dataset Principal\n",
    "Mescla os preços de carbono ao dataset principal com base no ano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Mesclar preços ao dataset principal\n",
    "df = df.merge(df_price, on='ano', how='inner')\n",
    "print(\"Dataset após merge:\", df.shape)\n",
    "# Visualizar as primeiras linhas do dataset mesclado\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregar Dados por Município e Ano\n",
    "Agrupa os dados por município e ano para evitar duplicações e mantém uma linha única por município-ano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1) Agregar dados por município e ano para evitar duplicações\n",
    "df = (\n",
    "    df.groupby(['municipio', 'ano'], as_index=False)\n",
    "      .agg({\n",
    "          'pib': 'first',                  # PIB já é único por muni-ano\n",
    "          'GEE_tCO2e': 'sum',              # soma emissões de todas as classes\n",
    "          'area_desmatada_ha': 'sum',      # soma área desmatada total\n",
    "          'carbon_price_usd': 'first'      # preço único por ano\n",
    "      })\n",
    ")\n",
    "print(\"Após agregação município-ano:\", df.shape)\n",
    "# Visualizar as primeiras linhas do dataset agregado\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar Features e Target\n",
    "Prepara as colunas de features e a variável target para o treinamento dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Preparar features e target\n",
    "feature_cols = FEATURE_COLS\n",
    "for col in feature_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "target_col = 'carbon_price_usd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisão Treino/Teste\n",
    "Divide os dados em conjuntos de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Divisão treino/teste\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padronização\n",
    "Padroniza os dados para melhorar o desempenho dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Padronização\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir e Treinar Modelos\n",
    "Define diferentes modelos de machine learning e realiza o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Definir e treinar modelos\n",
    "modelos = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'KNN Regressor': KNeighborsRegressor(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'MLP Regressor': MLPRegressor(max_iter=1000, random_state=42),\n",
    "    'Lasso': Lasso(alpha=0.01, random_state=42),\n",
    "    'SVR': SVR(kernel='rbf'),\n",
    "    'Dummy': DummyRegressor(),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in modelos.items():\n",
    "    print(f\"Treinando {name}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    preds = model.predict(X_test_scaled)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    print(f\"{name} → R²: {r2:.3f}, MSE: {mse:.3f}\")\n",
    "    results.append({'model': name, 'R2': r2, 'MSE': mse})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar Resultados\n",
    "Salva os resultados dos modelos em um arquivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Salvar resultados\n",
    "df_res = pd.DataFrame(results)\n",
    "df_res.to_csv(OUTPUT_PATHS.model_results_csv, index=False)\n",
    "print(\"Resultados salvos em:\", OUTPUT_PATHS.model_results_csv)\n",
    "# Visualizar os resultados\n",
    "display(df_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter Real vs Previsto – XGBoost\n",
    "Gera um gráfico de dispersão comparando os valores reais e previstos pelo modelo XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Scatter Real vs Previsto – XGBoost\n",
    "best = modelos['XGBoost']\n",
    "y_best = best.predict(X_test_scaled)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_test, y=y_best)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
    "plt.xlabel('Real')\n",
    "plt.ylabel('Previsto')\n",
    "plt.title('Real vs Previsto – XGBoost')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATHS.scatter_xgboost_png)\n",
    "print(\"Scatter salvo em:\", OUTPUT_PATHS.scatter_xgboost_png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
